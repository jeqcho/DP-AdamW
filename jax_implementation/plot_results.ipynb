{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of rows in each group:\n",
      "    learning_rate  weight_decay  adam_corr  count\n",
      "0         0.00003        0.0001      False      5\n",
      "1         0.00003        0.0001       True      5\n",
      "2         0.00003        0.0010      False      5\n",
      "3         0.00003        0.0010       True      5\n",
      "4         0.00003        0.0100      False      5\n",
      "5         0.00003        0.0100       True      5\n",
      "6         0.00005        0.0001      False      5\n",
      "7         0.00005        0.0001       True      5\n",
      "8         0.00005        0.0010      False      5\n",
      "9         0.00005        0.0010       True      5\n",
      "10        0.00005        0.0100      False      5\n",
      "11        0.00005        0.0100       True      5\n",
      "12        0.00007        0.0001      False      5\n",
      "13        0.00007        0.0001       True      5\n",
      "14        0.00007        0.0010      False      5\n",
      "15        0.00007        0.0010       True      5\n",
      "16        0.00007        0.0100      False      5\n",
      "17        0.00007        0.0100       True      5\n",
      "18        0.00010        0.0001      False      5\n",
      "19        0.00010        0.0001       True      5\n",
      "20        0.00010        0.0010      False      5\n",
      "21        0.00010        0.0010       True      5\n",
      "22        0.00010        0.0100      False      5\n",
      "23        0.00010        0.0100       True      5\n",
      "24        0.00020        0.0001      False      5\n",
      "25        0.00020        0.0001       True      5\n",
      "26        0.00020        0.0010      False      5\n",
      "27        0.00020        0.0010       True      5\n",
      "28        0.00020        0.0100      False      5\n",
      "29        0.00020        0.0100       True      5\n",
      "    learning_rate  weight_decay  adam_corr  best_test_accuracy\n",
      "19        0.00010        0.0001       True            0.507465\n",
      "20        0.00010        0.0010      False            0.507335\n",
      "22        0.00010        0.0100      False            0.507292\n",
      "18        0.00010        0.0001      False            0.506207\n",
      "23        0.00010        0.0100       True            0.505859\n",
      "21        0.00010        0.0010       True            0.505838\n",
      "17        0.00007        0.0100       True            0.494466\n",
      "13        0.00007        0.0001       True            0.494401\n",
      "12        0.00007        0.0001      False            0.493663\n",
      "16        0.00007        0.0100      False            0.493099\n",
      "15        0.00007        0.0010       True            0.492383\n",
      "14        0.00007        0.0010      False            0.492253\n",
      "8         0.00005        0.0010      False            0.477148\n",
      "24        0.00020        0.0001      False            0.475825\n",
      "10        0.00005        0.0100      False            0.475195\n",
      "28        0.00020        0.0100      False            0.475087\n",
      "25        0.00020        0.0001       True            0.475043\n",
      "9         0.00005        0.0010       True            0.475043\n",
      "26        0.00020        0.0010      False            0.474653\n",
      "6         0.00005        0.0001      False            0.474501\n",
      "29        0.00020        0.0100       True            0.474392\n",
      "7         0.00005        0.0001       True            0.474349\n",
      "27        0.00020        0.0010       True            0.474045\n",
      "11        0.00005        0.0100       True            0.474002\n",
      "2         0.00003        0.0010      False            0.439670\n",
      "0         0.00003        0.0001      False            0.438976\n",
      "1         0.00003        0.0001       True            0.438672\n",
      "4         0.00003        0.0100      False            0.438433\n",
      "3         0.00003        0.0010       True            0.438064\n",
      "5         0.00003        0.0100       True            0.437088\n"
     ]
    }
   ],
   "source": [
    "cifar1 = pd.read_csv('cifar_1.csv')\n",
    "aggregated_df = cifar1.groupby(['learning_rate', 'weight_decay', 'adam_corr'])['best_test_accuracy'].mean().reset_index()\n",
    "# Count number of rows in each group\n",
    "group_counts = cifar1.groupby(['learning_rate', 'weight_decay', 'adam_corr']).size().reset_index(name='count')\n",
    "print(\"\\nNumber of rows in each group:\")\n",
    "print(group_counts)\n",
    "\n",
    "aggregated_df = aggregated_df.sort_values('best_test_accuracy', ascending=False)\n",
    "print(aggregated_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of rows in each group:\n",
      "    learning_rate  weight_decay  adam_corr  count\n",
      "0         0.00005        0.0001      False      5\n",
      "1         0.00005        0.0001       True      5\n",
      "2         0.00005        0.0010      False      5\n",
      "3         0.00005        0.0010       True      5\n",
      "4         0.00005        0.0100      False      5\n",
      "5         0.00005        0.0100       True      5\n",
      "6         0.00007        0.0001      False      5\n",
      "7         0.00007        0.0001       True      5\n",
      "8         0.00007        0.0010      False      5\n",
      "9         0.00007        0.0010       True      5\n",
      "10        0.00007        0.0100      False      5\n",
      "11        0.00007        0.0100       True      5\n",
      "12        0.00010        0.0001      False      5\n",
      "13        0.00010        0.0001       True      5\n",
      "14        0.00010        0.0010      False      5\n",
      "15        0.00010        0.0010       True      5\n",
      "16        0.00010        0.0100      False      5\n",
      "17        0.00010        0.0100       True      5\n",
      "18        0.00020        0.0001      False      5\n",
      "19        0.00020        0.0001       True      5\n",
      "20        0.00020        0.0010      False      5\n",
      "21        0.00020        0.0010       True      5\n",
      "22        0.00020        0.0100      False      5\n",
      "23        0.00020        0.0100       True      5\n",
      "24        0.00030        0.0001      False      5\n",
      "25        0.00030        0.0001       True      5\n",
      "26        0.00030        0.0010      False      5\n",
      "27        0.00030        0.0010       True      5\n",
      "28        0.00030        0.0100      False      5\n",
      "29        0.00030        0.0100       True      5\n",
      "    learning_rate  weight_decay  adam_corr  best_test_accuracy\n",
      "12        0.00010        0.0001      False            0.562457\n",
      "15        0.00010        0.0010       True            0.562131\n",
      "14        0.00010        0.0010      False            0.560330\n",
      "13        0.00010        0.0001       True            0.559701\n",
      "16        0.00010        0.0100      False            0.559093\n",
      "17        0.00010        0.0100       True            0.558963\n",
      "20        0.00020        0.0010      False            0.552691\n",
      "22        0.00020        0.0100      False            0.552604\n",
      "19        0.00020        0.0001       True            0.551975\n",
      "23        0.00020        0.0100       True            0.551042\n",
      "18        0.00020        0.0001      False            0.550347\n",
      "21        0.00020        0.0010       True            0.550260\n",
      "11        0.00007        0.0100       True            0.543663\n",
      "8         0.00007        0.0010      False            0.543121\n",
      "9         0.00007        0.0010       True            0.542860\n",
      "7         0.00007        0.0001       True            0.542839\n",
      "6         0.00007        0.0001      False            0.542426\n",
      "10        0.00007        0.0100      False            0.538824\n",
      "26        0.00030        0.0010      False            0.522483\n",
      "3         0.00005        0.0010       True            0.519032\n",
      "0         0.00005        0.0001      False            0.518924\n",
      "1         0.00005        0.0001       True            0.518359\n",
      "2         0.00005        0.0010      False            0.518273\n",
      "4         0.00005        0.0100      False            0.517904\n",
      "28        0.00030        0.0100      False            0.516667\n",
      "5         0.00005        0.0100       True            0.516623\n",
      "29        0.00030        0.0100       True            0.516450\n",
      "27        0.00030        0.0010       True            0.516341\n",
      "24        0.00030        0.0001      False            0.516016\n",
      "25        0.00030        0.0001       True            0.515951\n"
     ]
    }
   ],
   "source": [
    "cifar3 = pd.read_csv('cifar_3.csv')\n",
    "aggregated_df = cifar3.groupby(['learning_rate', 'weight_decay', 'adam_corr'])['best_test_accuracy'].mean().reset_index()\n",
    "# Count number of rows in each group\n",
    "group_counts = cifar3.groupby(['learning_rate', 'weight_decay', 'adam_corr']).size().reset_index(name='count')\n",
    "print(\"\\nNumber of rows in each group:\")\n",
    "print(group_counts)\n",
    "\n",
    "aggregated_df = aggregated_df.sort_values('best_test_accuracy', ascending=False)\n",
    "print(aggregated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of rows in each group:\n",
      "    learning_rate  weight_decay  adam_corr  count\n",
      "0          0.0001        0.0001      False      5\n",
      "1          0.0001        0.0001       True      5\n",
      "2          0.0001        0.0010      False      5\n",
      "3          0.0001        0.0010       True      5\n",
      "4          0.0001        0.0100      False      5\n",
      "5          0.0001        0.0100       True      5\n",
      "6          0.0002        0.0001      False      5\n",
      "7          0.0002        0.0001       True      5\n",
      "8          0.0002        0.0010      False      5\n",
      "9          0.0002        0.0010       True      5\n",
      "10         0.0002        0.0100      False      5\n",
      "11         0.0002        0.0100       True      5\n",
      "12         0.0003        0.0001      False      5\n",
      "13         0.0003        0.0001       True      5\n",
      "14         0.0003        0.0010      False      5\n",
      "15         0.0003        0.0010       True      5\n",
      "16         0.0003        0.0100      False      5\n",
      "17         0.0003        0.0100       True      5\n",
      "18         0.0004        0.0001      False      5\n",
      "19         0.0004        0.0001       True      5\n",
      "20         0.0004        0.0010      False      5\n",
      "21         0.0004        0.0010       True      5\n",
      "22         0.0004        0.0100      False      5\n",
      "23         0.0004        0.0100       True      5\n",
      "24         0.0005        0.0001      False      5\n",
      "25         0.0005        0.0001       True      5\n",
      "26         0.0005        0.0010      False      5\n",
      "27         0.0005        0.0010       True      5\n",
      "28         0.0005        0.0100      False      5\n",
      "29         0.0005        0.0100       True      5\n",
      "30         0.0010        0.0001      False      4\n",
      "31         0.0010        0.0001       True      4\n",
      "32         0.0010        0.0010      False      4\n",
      "33         0.0010        0.0010       True      4\n",
      "34         0.0010        0.0100      False      5\n",
      "35         0.0010        0.0100       True      5\n",
      "36         0.0020        0.0001      False      3\n",
      "37         0.0020        0.0001       True      4\n",
      "38         0.0020        0.0010      False      3\n",
      "39         0.0020        0.0010       True      4\n",
      "40         0.0020        0.0100      False      5\n",
      "41         0.0020        0.0100       True      5\n",
      "42         0.0030        0.0001      False      3\n",
      "43         0.0030        0.0001       True      3\n",
      "44         0.0030        0.0010      False      3\n",
      "45         0.0030        0.0010       True      3\n",
      "46         0.0030        0.0100      False      5\n",
      "47         0.0030        0.0100       True      5\n",
      "48         0.0040        0.0001      False      3\n",
      "49         0.0040        0.0001       True      3\n",
      "50         0.0040        0.0010      False      3\n",
      "51         0.0040        0.0010       True      3\n",
      "52         0.0040        0.0100      False      4\n",
      "53         0.0040        0.0100       True      5\n",
      "54         0.0050        0.0001      False      3\n",
      "55         0.0050        0.0001       True      3\n",
      "56         0.0050        0.0010      False      3\n",
      "57         0.0050        0.0010       True      3\n",
      "58         0.0050        0.0100      False      4\n",
      "59         0.0050        0.0100       True      4\n",
      "    learning_rate  weight_decay  adam_corr  best_test_accuracy\n",
      "23         0.0004        0.0100       True            0.616374\n",
      "18         0.0004        0.0001      False            0.615560\n",
      "22         0.0004        0.0100      False            0.614909\n",
      "28         0.0005        0.0100      False            0.614800\n",
      "19         0.0004        0.0001       True            0.613824\n",
      "14         0.0003        0.0010      False            0.613770\n",
      "12         0.0003        0.0001      False            0.613661\n",
      "16         0.0003        0.0100      False            0.612901\n",
      "15         0.0003        0.0010       True            0.612088\n",
      "21         0.0004        0.0010       True            0.611654\n",
      "13         0.0003        0.0001       True            0.611437\n",
      "26         0.0005        0.0010      False            0.611003\n",
      "20         0.0004        0.0010      False            0.610460\n",
      "17         0.0003        0.0100       True            0.609592\n",
      "27         0.0005        0.0010       True            0.607205\n",
      "29         0.0005        0.0100       True            0.606011\n",
      "24         0.0005        0.0001      False            0.604058\n",
      "25         0.0005        0.0001       True            0.602648\n",
      "6          0.0002        0.0001      False            0.594889\n",
      "11         0.0002        0.0100       True            0.590007\n",
      "9          0.0002        0.0010       True            0.589572\n",
      "7          0.0002        0.0001       True            0.589464\n",
      "10         0.0002        0.0100      False            0.589030\n",
      "8          0.0002        0.0010      False            0.587674\n",
      "34         0.0010        0.0100      False            0.561914\n",
      "33         0.0010        0.0010       True            0.561659\n",
      "35         0.0010        0.0100       True            0.560178\n",
      "31         0.0010        0.0001       True            0.559625\n",
      "30         0.0010        0.0001      False            0.559570\n",
      "32         0.0010        0.0010      False            0.556478\n",
      "5          0.0001        0.0100       True            0.542426\n",
      "0          0.0001        0.0001      False            0.540744\n",
      "4          0.0001        0.0100      False            0.540310\n",
      "2          0.0001        0.0010      False            0.538032\n",
      "1          0.0001        0.0001       True            0.537652\n",
      "3          0.0001        0.0010       True            0.537055\n",
      "39         0.0020        0.0010       True            0.471761\n",
      "36         0.0020        0.0001      False            0.471246\n",
      "40         0.0020        0.0100      False            0.471072\n",
      "37         0.0020        0.0001       True            0.470459\n",
      "41         0.0020        0.0100       True            0.467925\n",
      "38         0.0020        0.0010      False            0.466905\n",
      "47         0.0030        0.0100       True            0.374631\n",
      "42         0.0030        0.0001      False            0.374349\n",
      "43         0.0030        0.0001       True            0.368815\n",
      "45         0.0030        0.0010       True            0.368200\n",
      "46         0.0030        0.0100      False            0.366688\n",
      "44         0.0030        0.0010      False            0.364764\n",
      "48         0.0040        0.0001      False            0.331887\n",
      "50         0.0040        0.0010      False            0.329897\n",
      "52         0.0040        0.0100      False            0.329102\n",
      "51         0.0040        0.0010       True            0.320964\n",
      "49         0.0040        0.0001       True            0.303313\n",
      "53         0.0040        0.0100       True            0.302626\n",
      "54         0.0050        0.0001      False            0.287833\n",
      "59         0.0050        0.0100       True            0.287082\n",
      "58         0.0050        0.0100      False            0.287082\n",
      "57         0.0050        0.0010       True            0.286314\n",
      "55         0.0050        0.0001       True            0.280056\n",
      "56         0.0050        0.0010      False            0.266710\n"
     ]
    }
   ],
   "source": [
    "cifar7 = pd.read_csv('cifar_7.csv')\n",
    "aggregated_df = cifar7.groupby(['learning_rate', 'weight_decay', 'adam_corr'])['best_test_accuracy'].mean().reset_index()\n",
    "# Count number of rows in each group\n",
    "group_counts = cifar7.groupby(['learning_rate', 'weight_decay', 'adam_corr']).size().reset_index(name='count')\n",
    "print(\"\\nNumber of rows in each group:\")\n",
    "print(group_counts)\n",
    "\n",
    "aggregated_df = aggregated_df.sort_values('best_test_accuracy', ascending=False)\n",
    "print(aggregated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp-adamw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
