12/25/2023 17:39:44:WARNING:Found cached dataset glue (/home/qiaoyuet/.cache/huggingface/datasets/glue/qnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
12/25/2023 17:39:45:WARNING:Found cached dataset glue (/home/qiaoyuet/.cache/huggingface/datasets/glue/qnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
/home/qiaoyuet/project/venvs/venv_nlp/lib/python3.10/site-packages/transformers/data/processors/glue.py:66: FutureWarning: This function will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py
  warnings.warn(DEPRECATION_WARNING.format("function"), FutureWarning)
Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.
Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/qiaoyuet/project/venvs/venv_nlp/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/qiaoyuet/project/venvs/venv_nlp/lib/python3.10/site-packages/opacus/accountants/analysis/prv/prvs.py:53: RuntimeWarning: divide by zero encountered in log
  t > np.log(1 - q),
Traceback (most recent call last):
  File "/home/qiaoyuet/project/dp_adam_bc_public/DP-AdamBC/pytorch_implementation/text_classification_glue.py", line 469, in <module>
    main()
  File "/home/qiaoyuet/project/dp_adam_bc_public/DP-AdamBC/pytorch_implementation/text_classification_glue.py", line 311, in main
    NOISE_MULTIPLIER = get_noise_multiplier(
  File "/home/qiaoyuet/project/venvs/venv_nlp/lib/python3.10/site-packages/opacus/accountants/utils.py", line 63, in get_noise_multiplier
    eps_high = accountant.get_epsilon(delta=target_delta, **kwargs)
  File "/home/qiaoyuet/project/venvs/venv_nlp/lib/python3.10/site-packages/opacus/accountants/prv.py", line 99, in get_epsilon
    _, _, eps_upper = dprv.compute_epsilon(delta, delta_error, eps_error)
  File "/home/qiaoyuet/project/venvs/venv_nlp/lib/python3.10/site-packages/opacus/accountants/analysis/prv/prvs.py", line 148, in compute_epsilon
    eps_upper = find_epsilon(delta - delta_error) + eps_error
  File "/home/qiaoyuet/project/venvs/venv_nlp/lib/python3.10/site-packages/opacus/accountants/analysis/prv/prvs.py", line 145, in find_epsilon
    raise RuntimeError("Cannot compute epsilon")
RuntimeError: Cannot compute epsilon